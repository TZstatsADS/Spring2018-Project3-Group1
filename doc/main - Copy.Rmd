---
title: "Model Selections and Feature Extractions"
author: "Wanting Cui, wc2619"
output:
  pdf_document: default
  html_document: default
---

```{r}
if(!require("xgboost")){
  install.packages("xgboost")
}

if(!require("ggplot2")){
  install.packages("ggplot2")
}

if(!require("reshape2")){
  install.packages("reshape2")
}

library(xgboost)
library(ggplot2)
library(reshape2)

source("../lib/xgboost_cv.R")
```

### Step 0: specify directories.

Set the working directory to the image folder. Specify the training and the testing set. For data without an independent test/validation set, you need to create your own testing data by random subsampling. In order to obain reproducible results, set.seed() whenever randomization is used. 

```{r}
lab_tr <- data.matrix(read.csv("../data/label_train.csv"))
train <- data.matrix(read.csv("../data/train.csv"))
test <- data.matrix(read.csv("../data/test.csv"))

fs.dir <- 
```


### Step 1: set up controls for evaluation experiments.

In this chunk, ,we have a set of controls for the evaluation experiments. 

+ (T/F) cross-validation on the training set
+ (number) K, the number of CV folds
+ (T/F) Use SIFT
+ (T/F) Use GIST
+ (T/F) Use HOG
+ (T/F) Use LBP
+ (T/F) run evaluation on an independent test set


```{r exp_setup}
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
# Please use one feature extraction method at a time
run.fs = TRUE # Use different feature extraction methods, if set "FALSE", will use SIFT as default
run.sift=TRUE # Use SIFT as the feature extraction method
run.gist=FALSE # Use GIST as the feature extraction method
run.hog=FALSE # Use HOG as the feature extraction method
run.LBP=FALSE # Use LBP as the feature extraction method
run.test=TRUE # run evaluation on an independent test set

```


### Step 2: import training images class labels.

For the example of zip code digits, we code digit 9 as "1" and digit 7 as "0" for binary classification.

```{r train_label}
lab_tr <- read.csv("../data/label_train.csv")
lab_tr <- data.matrix(lab_tr)
```

### Step 3: import training set from different feature extraction methods

For this simple example, we use the row averages of raw pixel values as the visual features. Note that this strategy **only** works for images with the same number of rows. For some other image datasets, the feature function should be able to handle heterogeneous input images. Save the constructed features to the output subfolder.

`feature.R` should be the wrapper for all your feature engineering functions and options. The function `feature( )` should have options that correspond to different scenarios for your project and produces an R object that contains features that are required by all the models you are going to evaluate later. 

```{r}
if(run.fs){
  if(run.sift){
     train_sift <- read.csv(paste0(fs_dir, "/train_sift.csv"))
     train_sift <- data.matrix(train_sift)
  }
  
  else if(run.gist){
    train_gist <- read.csv(paste0(fs_dir, "/gist10.csv"))
    train_gist <- data.matrix(train_gist)
  }
  
  else if(run.hog){
    load(paste0(fs_dir, "/HOG.RData"))
    train_hog <- data.matrix(dat)
  }
  
  else if(run.LBP){
    train_lbp <- read.csv(paste0(fs_dir, "/lbp/lbp.csv"))
    train_lbp <- data.matrix(train_lbp)
  }
 
} else {
  train_sift <- read.csv(paste0(fs_dir, "/train_sift.csv"))
  train_sift <- data.matrix(train_sift)
}
```

### Step 4: Train a classification model with training images

#### Model selection with cross-validation
* Do model selection by choosing among different values of training model parameters.
```{r runcv, message=FALSE, warning=FALSE}
if(run.cv){
  if(run.sift){
    sift_tr <- xgboost_cv(train = train_sift, lab = lab_tr, nrou = 100, 
                      list_max.depth = c(3, 5, 10, 20), 
                      list_eta = c(0.03, 0.3, 0.8),
                      name = "SIFT", fold = k)
    print(sift_tr[[2]])
  }
  
  else if(run.gist){
    gist_tr <- xgboost_cv(train = train_gist, lab = lab_tr, nrou = 100, 
                      list_max.depth = c(3, 5, 10, 20), 
                      list_eta = c(0.03, 0.3, 0.8),
                      name = "GIST", fold = k)
    print(gist_tr[[2]])
  }
  
  else if(run.hog){
    hog_tr <- xgboost_cv(train = train_hog, lab = lab_tr, nrou = 100, 
                      list_max.depth = c(3, 5, 10, 20), list_eta = c(0.03, 0.3, 0.8), 
                      name = "HOG", fold = k)
    print(hog_tr[[2]])
  }
  
  else if(run.LBP){
    lbp_tr <- xgboost_cv(train = train_lbp, lab = lab_tr, nrou = 100, 
                      list_max.depth = c(3, 5, 10, 20), list_eta = c(0.03, 0.3, 0.8), 
                      name = "LBP", fold = k)
    print(lbp_tr[[2]])
  }
}

```

According to previous results, tune parameters of the SIFT one even more

```{r}
sift_tr2 <- xgboost_cv(train = train_sift, lab = lab_tr, nrou = 60, 
                      list_max.depth = c(1,2,3,4), 
                      list_eta = c(0.5, 0.8, 0.9),
                      name = "SIFT2", fold = k)
sift_tr2[[2]]
```


* Train the model with the entire training set using the selected model (model parameter) via cross-validation.
```{r}
param <- list("objective" = "multi:softmax",
                    "num_class" = 4,
                    "eta" = 0.9, "max.depth" = 4)
t1 <- system.time(bst <- xgboost(data = train_sift, label = lab_tr, params = param, nrounds = 35, verbose = 0))
```

### Step 5: Make prediction 
Feed the final training model with the completely holdout testing data. 
```{r}
if(run.test){
  test <- data.matrix(read.csv("../data/test.csv"))
  lab_te <- data.matrix(read.csv("../data/label_test.csv"))
  
  t2 <- system.time(pred <- predict(bst, test))
  sum(pred != lab_te)/length(lab_te)
}
```

### Summarize Running Time
Prediction performance matters, so does the running times for constructing features and for training the model, especially when the computation resource is limited. 
```{r running_time}
cat("Time for training model is", t1[3], "s \n")
cat("Time for making prediction is", t2[3], "s \n")
```
